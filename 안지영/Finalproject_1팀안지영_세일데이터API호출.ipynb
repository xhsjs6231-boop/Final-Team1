{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXPUT5eRqgzNnLqSFspkq6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enti1701aaa/Final-Team1/blob/main/Finalproject_1%ED%8C%80%EC%95%88%EC%A7%80%EC%98%81_%EC%84%B8%EC%9D%BC%EB%8D%B0%EC%9D%B4%ED%84%B0API%ED%98%B8%EC%B6%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjyFtOm6rekT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/weighted_score_above_08.csv')"
      ],
      "metadata": {
        "id": "5fGl_76krkhB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ee3e338-81f6-48b5-9850-1d06fbd5885d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1023940785.py:1: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/weighted_score_above_08.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Í≥µÌÜµ Ï†ÑÏ≤òÎ¶¨"
      ],
      "metadata": {
        "id": "Fk0I3s2_zgBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑÎ•º ÎÇ†ÏßúÎç∞Ïù¥ÌÑ∞Î°ú Î≥ÄÌôò\n",
        "df[['timestamp_created', 'timestamp_updated','author_last_played']] = df[['timestamp_created', 'timestamp_updated','author_last_played']].apply(\n",
        "    pd.to_datetime, unit='s'\n",
        ")"
      ],
      "metadata": {
        "id": "JXgm6-sBzjyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5ÎÖÑ Ïù¥ÎÇ¥ Îç∞Ïù¥ÌÑ∞ ÏÇ¨Ïö©\n",
        "\n",
        "# timestamp_created Ï¶â Î¶¨Î∑∞ ÏûëÏÑ±ÏùºÏûê\n",
        "# 1. Í∞ÄÏû• ÏµúÏã† ÎÇ†Ïßú Íµ¨ÌïòÍ∏∞\n",
        "latest_date = df['timestamp_created'].max()\n",
        "\n",
        "# 2. 5ÎÖÑ Ï†Ñ cutoff Í≥ÑÏÇ∞\n",
        "cutoff_date = latest_date - pd.DateOffset(years=5)\n",
        "\n",
        "# 3. ÌïÑÌÑ∞ÎßÅ (5ÎÖÑ Ïù¥ÎÇ¥ Îç∞Ïù¥ÌÑ∞Îßå ÎÇ®ÍπÄ)\n",
        "df= df[df['timestamp_created'] >= cutoff_date].copy()"
      ],
      "metadata": {
        "id": "RM2if9zQ0ALz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Î¶¨Î∑∞Ïñ¥ ÌäπÏÑ± Ï†ÑÏ≤òÎ¶¨\n",
        "df = df[(df['author_num_reviews'] != 0)\n",
        "  & (df[\"author_num_games_owned\"] != 0)\n",
        "  & (df['author_playtime_forever'] != 0)\n",
        "  & (df[\"author_playtime_at_review\"] != 0)]"
      ],
      "metadata": {
        "id": "NB5zGhnt0Kpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ïù¥ÏÉÅÏπòÍ∏∞Ï§ÄÏúºÎ°ú ÏùºÎ∞ò/ÏΩîÏñ¥Ïú†Ï†Ä Íµ¨Î∂Ñ\n",
        "\n",
        "# Î∂ÑÏÑù ÎåÄÏÉÅ Ïª¨Îüº Ï†ïÏùò\n",
        "cols = [\n",
        "    'author_num_games_owned',\n",
        "    'author_num_reviews',\n",
        "    'author_playtime_forever',\n",
        "    'author_playtime_last_two_weeks',\n",
        "    'author_playtime_at_review',\n",
        "    'author_last_played'\n",
        "]\n",
        "\n",
        "numeric_cols = df[cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Î∂ÑÏúÑÏàò Í≥ÑÏÇ∞\n",
        "Q1 = numeric_cols.quantile(0.25)\n",
        "Q3 = numeric_cols.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Ïù¥ÏÉÅÏπò Í≤ΩÍ≥Ñ Í≥ÑÏÇ∞\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Ïù¥ÏÉÅÏπò Ïó¨Î∂Ä ÌÉúÍπÖ\n",
        "df['is_outlier'] = ((numeric_cols < lower_bound) | (numeric_cols > upper_bound)).any(axis=1)\n",
        "\n",
        "# Îëê Í∑∏Î£π Î∂ÑÎ¶¨\n",
        "df_general = df[df['is_outlier'] == False]   # ÏùºÎ∞ò Ïú†Ï†ÄÍµ∞ (ÎåÄÏÑ∏ Ìä∏Î†åÎìúÏö©)\n",
        "df_core    = df[df['is_outlier'] == True]    # ÌïµÏã¨/ÌäπÏàò Ïú†Ï†ÄÍµ∞ (ÏÉÅÏúÑ/ÌïòÏúÑ ÌäπÏù¥ Ìå®ÌÑ¥Ïö©)\n",
        "\n",
        "# -----------------------\n",
        "# ÏòàÏãú Î∂ÑÏÑù: Î∂ÑÏúÑÏàò Í∏∞Î∞ò ÏöîÏïΩ\n",
        "# -----------------------\n",
        "\n",
        "# ÏùºÎ∞ò Ïú†Ï†Ä Ìä∏Î†åÎìú\n",
        "general_stats = df_general[cols].describe(percentiles=[0.5, 0.75, 0.9, 0.95])\n",
        "\n",
        "# ÌïµÏã¨ Ïú†Ï†Ä ÌäπÏù¥ Ìå®ÌÑ¥\n",
        "core_stats = df_core[cols].describe(percentiles=[0.5, 0.75, 0.9, 0.95])\n",
        "\n",
        "print(\"üìä ÏùºÎ∞ò Ïú†Ï†Ä Ìä∏Î†åÎìú ÏöîÏïΩ:\")\n",
        "print(general_stats)\n",
        "\n",
        "print(\"\\nüî• ÌïµÏã¨ Ïú†Ï†Ä(Ïù¥ÏÉÅÏπò) Ìå®ÌÑ¥ ÏöîÏïΩ:\")\n",
        "print(core_stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nksJKZS0QHJ",
        "outputId": "65f2282f-b49e-4e32-a3fb-525568655034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä ÏùºÎ∞ò Ïú†Ï†Ä Ìä∏Î†åÎìú ÏöîÏïΩ:\n",
            "       author_num_games_owned  author_num_reviews  author_playtime_forever  \\\n",
            "count           138601.000000       138601.000000            138601.000000   \n",
            "mean               202.219262           19.168000              1805.426043   \n",
            "min                  1.000000            1.000000                 1.000000   \n",
            "50%                138.000000           12.000000               840.000000   \n",
            "75%                274.000000           27.000000              2429.000000   \n",
            "90%                476.000000           49.000000              5011.000000   \n",
            "95%                625.000000           64.000000              6894.000000   \n",
            "max                941.000000           92.000000             13357.000000   \n",
            "std                189.090592           19.760682              2360.477106   \n",
            "\n",
            "       author_playtime_last_two_weeks  author_playtime_at_review  \\\n",
            "count                        138601.0              138601.000000   \n",
            "mean                              0.0                 884.667167   \n",
            "min                               0.0                   1.000000   \n",
            "50%                               0.0                 363.000000   \n",
            "75%                               0.0                1142.000000   \n",
            "90%                               0.0                2625.000000   \n",
            "95%                               0.0                3738.000000   \n",
            "max                               0.0                5917.000000   \n",
            "std                               0.0                1204.423236   \n",
            "\n",
            "                  author_last_played  \n",
            "count                         138601  \n",
            "mean   2022-05-09 04:15:34.615060224  \n",
            "min              2018-09-03 16:28:32  \n",
            "50%              2022-09-06 00:22:21  \n",
            "75%              2023-05-20 18:11:31  \n",
            "90%              2023-08-27 10:47:02  \n",
            "95%              2023-09-24 08:57:42  \n",
            "max              2023-10-20 10:30:19  \n",
            "std                              NaN  \n",
            "\n",
            "üî• ÌïµÏã¨ Ïú†Ï†Ä(Ïù¥ÏÉÅÏπò) Ìå®ÌÑ¥ ÏöîÏïΩ:\n",
            "       author_num_games_owned  author_num_reviews  author_playtime_forever  \\\n",
            "count            83050.000000        83050.000000             8.305000e+04   \n",
            "mean              1196.868356          147.962962             3.626860e+04   \n",
            "min                  1.000000            1.000000             1.000000e+00   \n",
            "50%                335.000000           26.000000             6.835000e+03   \n",
            "75%               1189.750000          120.000000             2.529300e+04   \n",
            "90%               2714.000000          322.000000             8.067510e+04   \n",
            "95%               5790.000000          615.000000             1.505603e+05   \n",
            "max              30425.000000        10413.000000             5.440698e+06   \n",
            "std               2394.669679          406.756632             1.233108e+05   \n",
            "\n",
            "       author_playtime_last_two_weeks  author_playtime_at_review  \\\n",
            "count                    83050.000000               8.305000e+04   \n",
            "mean                       237.443095               1.898101e+04   \n",
            "min                          0.000000               1.000000e+00   \n",
            "50%                          0.000000               2.087000e+03   \n",
            "75%                          0.000000               1.087575e+04   \n",
            "90%                        278.000000               4.213000e+04   \n",
            "95%                       1014.000000               8.100110e+04   \n",
            "max                      20154.000000               4.776595e+06   \n",
            "std                       1322.344483               7.350553e+04   \n",
            "\n",
            "                  author_last_played  \n",
            "count                          83050  \n",
            "mean   2022-07-21 08:09:52.935038976  \n",
            "min              1970-01-02 00:00:00  \n",
            "50%              2023-03-16 15:27:10  \n",
            "75%       2023-10-10 22:29:03.500000  \n",
            "90%       2023-10-26 18:04:49.600000  \n",
            "95%    2023-10-30 22:41:28.550000128  \n",
            "max              2023-11-03 21:50:19  \n",
            "std                              NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ÏÑ∏Ïùº Ïù¥Î≤§Ìä∏ ÏàòÏßë"
      ],
      "metadata": {
        "id": "yLrQtRYbx-Vt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ïú†Ìö® Î¶¨Î∑∞ ÌïÑÌÑ∞ÎßÅ\n",
        " - ÌîÑÎ°úÎ™®ÏÖòÏúºÎ°ú Î¨¥Î£å ÌöçÎìùÌïú Ïú†Ï†Ä (received_for_free=True)\n",
        " - Ïô∏Î∂Ä ÌÇ§(Î≤àÎì§, Îã§Î•∏ ÌîåÎû´Ìèº Îì±)Î°ú Îì±Î°ùÌïú Ïú†Ï†Ä(steam_purchase == 0)"
      ],
      "metadata": {
        "id": "6efPuTcSysCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df[(df[\"received_for_free\"] == 0) & (df[\"steam_purchase\"] == 1)].copy()\n",
        "\n",
        "print(\"ÏõêÎ≥∏ Î¶¨Î∑∞ Ïàò:\", len(df))\n",
        "print(\"ÌïÑÌÑ∞ÎßÅ ÌõÑ Î¶¨Î∑∞ Ïàò:\", len(df_filtered))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_ln3Jhvxrk8",
        "outputId": "3806f0f7-64f2-44a1-9554-2bd811d115b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÏõêÎ≥∏ Î¶¨Î∑∞ Ïàò: 221651\n",
            "ÌïÑÌÑ∞ÎßÅ ÌõÑ Î¶¨Î∑∞ Ïàò: 149105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Î¨¥Î£åÍ≤åÏûÑ(F2P)Ï†úÍ±∞\n",
        "- Steam Storefront appdetail ÏÇ¨Ïö©"
      ],
      "metadata": {
        "id": "Flw0YbB5y5ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, time, math, os, json, pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "REVIEW_CSV = \"weighted_score_above_08.csv\"   # ÌååÏùºÍ≤ΩÎ°ú\n",
        "CACHE_CSV  = \"appid_isfree_cache.csv\"        # Ï§ëÍ∞Ñ Ï∫êÏãú\n",
        "OUT_META   = \"appid_meta_final.csv\"          # ÏµúÏ¢Ö Î©îÌÉÄ Í≤∞Í≥º\n",
        "OUT_MERGED = \"steam_review_filtered.csv\"     # Î¨¥Î£å/ÎπÑÎ≥∏Ìé∏ Ï†úÍ±∞Îêú ÏµúÏ¢Ö Î¶¨Î∑∞"
      ],
      "metadata": {
        "id": "2XL7tkMK6upS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# appid Í≥†Ïú† Î™©Î°ù Ï∂îÏ∂ú\n",
        "\n",
        "appids = (\n",
        "    df_filtered['appid']\n",
        "    .dropna()\n",
        "    .astype(int)\n",
        "    .drop_duplicates()\n",
        "    .tolist()\n",
        ")\n",
        "print(f\"Unique appids: {len(appids):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVJuICdN9gl0",
        "outputId": "d47cad6e-b8a3-4629-88e8-493e79e26844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique appids: 9,606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ï∫êÏãú ÌååÏùº Î∂àÎü¨Ïò§Í∏∞(Ïã§Ìå®Ïãú Î¶¨Ïä§ÌÅ¨ Ï∂ïÏÜå)\n",
        "need_cols = ['appid','is_free','type','ok','error']\n",
        "if os.path.exists(CACHE_CSV):\n",
        "    cache = pd.read_csv(CACHE_CSV)\n",
        "    if 'appid' in cache:\n",
        "        cache['appid'] = cache['appid'].astype(int, errors='ignore')\n",
        "    # ÎàÑÎùΩ Ïª¨Îüº Î≥¥Í∞ï\n",
        "    for c in need_cols:\n",
        "        if c not in cache.columns:\n",
        "            cache[c] = None\n",
        "    cache = cache[need_cols].drop_duplicates(subset=['appid'], keep='last')\n",
        "else:\n",
        "    cache = pd.DataFrame(columns=need_cols)\n",
        "\n",
        "done_appids = set(cache['appid'].tolist())\n",
        "todo_appids = [a for a in appids if a not in done_appids]\n",
        "print(f\"Cached: {len(done_appids):,} | To fetch: {len(todo_appids):,}\")\n",
        "\n",
        "# Îã®Ïùº appid Ï°∞Ìöå (F2P Ïó¨Î∂ÄÎßå ÌôïÎ≥¥)\n",
        "def fetch_appdetails(appid, max_retries=3, cooldown=0.5):\n",
        "    url = f\"https://store.steampowered.com/api/appdetails?appids={appid}&cc=us&l=en\"\n",
        "    for attempt in range(1, max_retries+1):\n",
        "        try:\n",
        "            r = requests.get(url, timeout=10)\n",
        "            r.raise_for_status()\n",
        "            js = r.json()\n",
        "            rec = js.get(str(appid), {})\n",
        "            if not rec or not rec.get('success'):\n",
        "                return {\"appid\": appid, \"is_free\": None, \"type\": None, \"ok\": False, \"error\": \"success_false_or_no_data\"}\n",
        "            data = rec.get('data', {})\n",
        "            return {\n",
        "                \"appid\": appid,\n",
        "                \"is_free\": data.get(\"is_free\", None),  # True / False / None\n",
        "                \"type\": data.get(\"type\", None),        # ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÏßÄÎßå Ï∫êÏãú Ìò∏Ìôò ÏúÑÌï¥ Ï†ÄÏû•\n",
        "                \"ok\": True,\n",
        "                \"error\": None\n",
        "            }\n",
        "        except Exception as e:\n",
        "            err = str(e)[:200]\n",
        "            if attempt < max_retries:\n",
        "                time.sleep(cooldown * attempt)  # Ï†êÏ†ê ÎäòÏñ¥ÎÇòÎäî ÎåÄÍ∏∞\n",
        "            else:\n",
        "                return {\"appid\": appid, \"is_free\": None, \"type\": None, \"ok\": False, \"error\": err}\n",
        "\n",
        "# Ï°∞Ìöå Î£®ÌîÑ (Î†àÏù¥Ìä∏ Ï†úÌïú Í≥†Î†§)\n",
        "rows = []\n",
        "for a in tqdm(todo_appids, desc=\"Fetching appdetails\"):\n",
        "    rows.append(fetch_appdetails(a))\n",
        "    time.sleep(0.4)  # ÏÜçÎèÑ Ï°∞Ï†à (ÌïÑÏöîÏãú Ï°∞Ï†ï)\n",
        "\n",
        "# Ï∫êÏãúÏóê Ìï©ÏπòÍ≥† Ï†ÄÏû•\n",
        "if rows:\n",
        "    part = pd.DataFrame(rows)\n",
        "    cache = pd.concat([cache, part], ignore_index=True)\n",
        "    # Ï§ëÎ≥µ appidÍ∞Ä ÏûàÎã§Î©¥ ÎßàÏßÄÎßâ Í≤∞Í≥ºÎßå ÎÇ®Í∏∞Í∏∞\n",
        "    cache = cache.drop_duplicates(subset=['appid'], keep='last')\n",
        "    cache.to_csv(CACHE_CSV, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLVNtmX09pDk",
        "outputId": "f73ca6f4-2983-46fb-beaf-71cdf27f1ab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cached: 0 | To fetch: 9,606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching appdetails: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9606/9606 [2:49:50<00:00,  1.06s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÏµúÏ¢Ö Ï†ïÎ¶¨Î≥∏ Ï†ÄÏû•\n",
        "meta = cache[['appid','is_free','type','ok','error']].copy()\n",
        "meta.to_csv(OUT_META, index=False)\n",
        "print(f\"Saved meta: {OUT_META} ({len(meta):,} rows)\")\n",
        "\n",
        "# Î¶¨Î∑∞ DFÏôÄ merge\n",
        "m = df_filtered.merge(meta[['appid','is_free']], on='appid', how='left')\n",
        "\n",
        "# F2P ÌîåÎûòÍ∑∏ Ïª¨Îüº: True/False/None Ïú†ÏßÄ\n",
        "m['f2p'] = m['is_free']\n",
        "\n",
        "# ÏöîÏïΩ Î¶¨Ìè¨Ìä∏\n",
        "total = len(m)\n",
        "cnt_true  = (m['f2p'] == True).sum()\n",
        "cnt_false = (m['f2p'] == False).sum()\n",
        "cnt_none  = m['f2p'].isna().sum()\n",
        "print(f\"Reviews: {total:,} | f2p=True: {cnt_true:,} | f2p=False: {cnt_false:,} | f2p=None: {cnt_none:,}\")\n",
        "\n",
        "# Ï†ÄÏû•\n",
        "m.to_csv(OUT_MERGED, index=False)\n",
        "print(f\"Saved reviews with f2p flag: {OUT_MERGED}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byL_VNMVED-X",
        "outputId": "69e05cd6-6768-4543-9eb6-a4b458ba0136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved meta: appid_meta_final.csv (9,606 rows)\n",
            "Reviews: 149,105 | f2p=True: 2,826 | f2p=False: 104,267 | f2p=None: 42,012\n",
            "Saved reviews with f2p flag: steam_review_filtered.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# f2p=False Ïù∏ Í≤ÉÎßå ÎÇ®Í∏∞Í∏∞\n",
        "\n",
        "f2p_norm = m['f2p'].map({True: True, False: False, 'True': True, 'False': False, 1: True, 0: False})\n",
        "m_f2p_false = m[f2p_norm == False].copy()\n",
        "print(len(m), \"->\", len(m_f2p_false))\n",
        "\n",
        "m_f2p_false.to_csv(\"steam_review_f2p_false.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwbGb_1iGerJ",
        "outputId": "a5801649-eeb3-497b-891e-1209feb9fcd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-845961437.py:2: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  m=pd.read_csv(\"/content/steam_review_filtered.csv\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "149105 -> 104267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ÌîåÎû´Ìèº ÏÑ∏Ïùº ÌûàÏä§ÌÜ†Î¶¨ ÏàòÏßë\n",
        "- SteamDB Sales History ÌÅ¨Î°§ÎßÅ"
      ],
      "metadata": {
        "id": "UYoChN-y7tLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "T60ZxlCj8FnG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "033fa447-4513-42de-c4a1-1111b59ebc6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-66ff0415-71d7-42f7-bb6a-8f5209a962e7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-66ff0415-71d7-42f7-bb6a-8f5209a962e7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Steam Sale Date.html to Steam Sale Date.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "html_file = next(iter(uploaded.keys()))\n",
        "print(\"uploaded:\", html_file)"
      ],
      "metadata": {
        "id": "c0Y8fBxV8Xq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08662427-c731-4a61-bc34-635211b6394f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uploaded: Steam Sale Date.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re, pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from dateutil import parser as dparser\n",
        "\n",
        "DATE_LINE_RE = re.compile(r\"(\\d{1,2}\\s+[A-Za-z]+(?:\\s+\\d{4})?)\\s+‚Äî\\s+(\\d{1,2}\\s+[A-Za-z]+(?:\\s+\\d{4})?)\")\n",
        "\n",
        "def nearest_year_from_heading(tag):\n",
        "    cur = tag\n",
        "    while cur:\n",
        "        cur = cur.find_previous([\"h3\",\"h2\"])\n",
        "        if cur:\n",
        "            m = re.search(r\"\\b(19|20)\\d{2}\\b\", cur.get_text(strip=True))\n",
        "            if m: return int(m.group(0))\n",
        "    return pd.Timestamp.utcnow().year\n",
        "\n",
        "def parse_date_range(date_text, default_year):\n",
        "    m = DATE_LINE_RE.search(date_text or \"\")\n",
        "    if not m:\n",
        "        parts = (date_text or \"\").split(\"‚Äî\")\n",
        "        if len(parts)==2:\n",
        "            left, right = parts[0].strip(), parts[1].strip()\n",
        "            mon = re.search(r\"[A-Za-z]+\", right)\n",
        "            if mon: left = f\"{left} {mon.group(0)}\"\n",
        "            m = DATE_LINE_RE.search(f\"{left} ‚Äî {right}\")\n",
        "    if not m: return None, None\n",
        "    s_raw, e_raw = m.group(1), m.group(2)\n",
        "\n",
        "    def ensure_year(s, y):\n",
        "        return s if re.search(r\"\\b(19|20)\\d{2}\\b\", s) else f\"{s} {y}\"\n",
        "\n",
        "    s_txt = ensure_year(s_raw, default_year)\n",
        "\n",
        "    # Ï¢ÖÎ£å Ïó∞ÎèÑ Î≥¥Ï†ï(12Ïõî‚ÜíÎã§ÏùåÌï¥ 1Ïõî ÏºÄÏù¥Ïä§)\n",
        "    if not re.search(r\"\\b(19|20)\\d{2}\\b\", e_raw):\n",
        "        s_dt_tmp = dparser.parse(s_txt, dayfirst=True, fuzzy=True)\n",
        "        e_txt_tmp = f\"{e_raw} {default_year}\"\n",
        "        e_dt_tmp = dparser.parse(e_txt_tmp, dayfirst=True, fuzzy=True)\n",
        "        e_txt = f\"{e_raw} {default_year+1}\" if e_dt_tmp.month < s_dt_tmp.month else e_txt_tmp\n",
        "    else:\n",
        "        e_txt = e_raw\n",
        "\n",
        "    s_dt = pd.to_datetime(s_txt, utc=True, dayfirst=True, errors=\"coerce\").normalize()\n",
        "    e_dt = pd.to_datetime(e_txt, utc=True, dayfirst=True, errors=\"coerce\").normalize()\n",
        "    return s_dt, e_dt\n",
        "\n",
        "def classify_event(name: str):\n",
        "    n = name.lower()\n",
        "    if \"sale\" in n:\n",
        "        if any(k in n for k in [\"summer\",\"winter\",\"autumn\",\"spring\"]): return \"seasonal_sale\"\n",
        "        return \"sale\"\n",
        "    if \"fest\" in n: return \"fest_next\" if \"next fest\" in n else \"fest\"\n",
        "    return \"other\"\n",
        "\n",
        "# HTML ÏùΩÍ≥† ÌååÏã±\n",
        "with open(html_file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "    html = f.read()\n",
        "soup = BeautifulSoup(html, \"lxml\")\n",
        "\n",
        "BASE = \"https://steamdb.info\"\n",
        "events = []\n",
        "for h4 in soup.find_all(\"h4\"):\n",
        "    title = h4.get_text(\" \", strip=True).replace(\"‚Ä¶\",\"\").strip()\n",
        "    a = h4.find(\"a\")\n",
        "    link = a[\"href\"] if (a and a.has_attr(\"href\")) else None\n",
        "    if link and link.startswith(\"/\"): link = BASE + link\n",
        "\n",
        "    # h4 Ïù∏Ï†ë ÌÖçÏä§Ìä∏ÏóêÏÑú ÎÇ†Ïßú ÎùºÏù∏ Ï∞æÍ∏∞\n",
        "    date_text, steps, sib = None, 0, h4.next_sibling\n",
        "    while sib and steps < 6 and date_text is None:\n",
        "        txt = sib.get_text(\" \", strip=True) if hasattr(sib, \"get_text\") else str(sib).strip()\n",
        "        if \"‚Äî\" in txt and re.search(r\"[A-Za-z]+\", txt):\n",
        "            if DATE_LINE_RE.search(txt) or re.search(r\"\\d{1,2}\\s*‚Äî\\s*\\d{1,2}\\s+[A-Za-z]+\", txt):\n",
        "                date_text = txt; break\n",
        "        sib = sib.next_sibling; steps += 1\n",
        "\n",
        "    year_ctx = nearest_year_from_heading(h4)\n",
        "    s_dt, e_dt = parse_date_range(date_text, year_ctx)\n",
        "    if s_dt is None or e_dt is None:\n",
        "        continue\n",
        "\n",
        "    events.append({\n",
        "        \"event_name\": title,\n",
        "        \"source_url\": link,\n",
        "        \"year_context\": year_ctx,\n",
        "        \"date_text_raw\": date_text,\n",
        "        \"start_utc\": s_dt,\n",
        "        \"end_utc\": e_dt,\n",
        "        \"event_type\": classify_event(title),\n",
        "    })\n",
        "\n",
        "df = (pd.DataFrame(events)\n",
        "        .drop_duplicates(subset=[\"event_name\",\"start_utc\",\"end_utc\"])\n",
        "        .sort_values([\"start_utc\",\"end_utc\",\"event_name\"], ascending=[False, False, True])\n",
        "        .reset_index(drop=True))\n",
        "\n",
        "df.to_csv(\"steamdb_valve_events_history.csv\", index=False)\n",
        "print(\"Saved:\", \"steamdb_valve_events_history.csv\", \"| rows:\", len(df))\n",
        "df.head(20)"
      ],
      "metadata": {
        "id": "r9lXj4iA8km_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "abcd226d-8ddb-474c-db72-95289860e7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: steamdb_valve_events_history.csv | rows: 207\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         event_name  \\\n",
              "0                  Winter Sale 2025   \n",
              "1                       Sports Fest   \n",
              "2                       Animal Fest   \n",
              "3            Steam Scream Fest 2025   \n",
              "4           Next Fest: October 2025   \n",
              "5                  Autumn Sale 2025   \n",
              "6                Political Sim Fest   \n",
              "7   Third Person Shooter (TPS) Fest   \n",
              "8                           4X Fest   \n",
              "9                       Racing Fest   \n",
              "10                  Automation Fest   \n",
              "11                 Summer Sale 2025   \n",
              "12                     Fishing Fest   \n",
              "13             Next Fest: June 2025   \n",
              "14        Zombies vs. Vampires Fest   \n",
              "15                       Ocean Fest   \n",
              "16          Creature Collector Fest   \n",
              "17                Deckbuilders Fest   \n",
              "18                    Wargames Fest   \n",
              "19       Box-Pushing (Sokoban) Fest   \n",
              "\n",
              "                                           source_url  year_context  \\\n",
              "0   https://steamcommunity.com/groups/steamworks/a...          2025   \n",
              "1   https://steamcommunity.com/groups/steamworks/a...          2025   \n",
              "2   https://steamcommunity.com/groups/steamworks/a...          2025   \n",
              "3   https://steamcommunity.com/groups/steamworks/a...          2025   \n",
              "4   https://steamcommunity.com/groups/store_promos...          2025   \n",
              "5   https://steamcommunity.com/groups/steamworks/a...          2025   \n",
              "6   https://steamcommunity.com/groups/store_promos...          2025   \n",
              "7   https://steamcommunity.com/groups/store_promos...          2025   \n",
              "8   https://steamcommunity.com/groups/store_promos...          2025   \n",
              "9   https://steamcommunity.com/groups/store_promos...          2025   \n",
              "10  https://steamcommunity.com/groups/steamworks/a...          2025   \n",
              "11  https://steamcommunity.com/games/593110/announ...          2025   \n",
              "12  https://steamcommunity.com/games/593110/announ...          2025   \n",
              "13  https://steamcommunity.com/games/593110/announ...          2025   \n",
              "14  https://steamcommunity.com/games/593110/announ...          2025   \n",
              "15  https://steamcommunity.com/groups/steamworks/a...          2025   \n",
              "16  https://steamcommunity.com/games/593110/announ...          2025   \n",
              "17  https://steamcommunity.com/groups/steamworks/a...          2025   \n",
              "18  https://steamcommunity.com/games/593110/announ...          2025   \n",
              "19  https://steamcommunity.com/games/593110/announ...          2025   \n",
              "\n",
              "                   date_text_raw                 start_utc  \\\n",
              "0   18 December ‚Äî 5 January 2026 2025-12-18 00:00:00+00:00   \n",
              "1                8 ‚Äî 15 December 2025-12-08 00:00:00+00:00   \n",
              "2               10 ‚Äî 17 November 2025-11-10 00:00:00+00:00   \n",
              "3        27 October ‚Äî 3 November 2025-10-27 00:00:00+00:00   \n",
              "4                13 ‚Äî 20 October 2025-10-13 00:00:00+00:00   \n",
              "5       29 September ‚Äî 6 October 2025-09-29 00:00:00+00:00   \n",
              "6               8 ‚Äî 15 September 2025-09-08 00:00:00+00:00   \n",
              "7        25 August ‚Äî 1 September 2025-08-25 00:00:00+00:00   \n",
              "8                 11 ‚Äî 18 August 2025-08-11 00:00:00+00:00   \n",
              "9             28 July ‚Äî 4 August 2025-07-28 00:00:00+00:00   \n",
              "10                  14 ‚Äî 21 July 2025-07-14 00:00:00+00:00   \n",
              "11             26 June ‚Äî 10 July 2025-06-26 00:00:00+00:00   \n",
              "12                  16 ‚Äî 23 June 2025-06-16 00:00:00+00:00   \n",
              "13                   9 ‚Äî 16 June 2025-06-09 00:00:00+00:00   \n",
              "14               26 May ‚Äî 2 June 2025-05-26 00:00:00+00:00   \n",
              "15                   18 ‚Äî 25 May 2025-05-18 00:00:00+00:00   \n",
              "16                   12 ‚Äî 19 May 2025-05-12 00:00:00+00:00   \n",
              "17                    4 ‚Äî 11 May 2025-05-04 00:00:00+00:00   \n",
              "18              28 April ‚Äî 5 May 2025-04-28 00:00:00+00:00   \n",
              "19                 21 ‚Äî 28 April 2025-04-21 00:00:00+00:00   \n",
              "\n",
              "                     end_utc     event_type  \n",
              "0  2026-01-05 00:00:00+00:00  seasonal_sale  \n",
              "1  2025-12-15 00:00:00+00:00           fest  \n",
              "2  2025-11-17 00:00:00+00:00           fest  \n",
              "3  2025-11-03 00:00:00+00:00           fest  \n",
              "4  2025-10-20 00:00:00+00:00      fest_next  \n",
              "5  2025-10-06 00:00:00+00:00  seasonal_sale  \n",
              "6  2025-09-15 00:00:00+00:00           fest  \n",
              "7  2025-09-01 00:00:00+00:00           fest  \n",
              "8  2025-08-18 00:00:00+00:00           fest  \n",
              "9  2025-08-04 00:00:00+00:00           fest  \n",
              "10 2025-07-21 00:00:00+00:00           fest  \n",
              "11 2025-07-10 00:00:00+00:00  seasonal_sale  \n",
              "12 2025-06-23 00:00:00+00:00           fest  \n",
              "13 2025-06-16 00:00:00+00:00      fest_next  \n",
              "14 2025-06-02 00:00:00+00:00           fest  \n",
              "15 2025-05-25 00:00:00+00:00           fest  \n",
              "16 2025-05-19 00:00:00+00:00           fest  \n",
              "17 2025-05-11 00:00:00+00:00           fest  \n",
              "18 2025-05-05 00:00:00+00:00           fest  \n",
              "19 2025-04-28 00:00:00+00:00           fest  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dca8a7f2-c480-4f4b-89fc-2350b091438d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>event_name</th>\n",
              "      <th>source_url</th>\n",
              "      <th>year_context</th>\n",
              "      <th>date_text_raw</th>\n",
              "      <th>start_utc</th>\n",
              "      <th>end_utc</th>\n",
              "      <th>event_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Winter Sale 2025</td>\n",
              "      <td>https://steamcommunity.com/groups/steamworks/a...</td>\n",
              "      <td>2025</td>\n",
              "      <td>18 December ‚Äî 5 January 2026</td>\n",
              "      <td>2025-12-18 00:00:00+00:00</td>\n",
              "      <td>2026-01-05 00:00:00+00:00</td>\n",
              "      <td>seasonal_sale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sports Fest</td>\n",
              "      <td>https://steamcommunity.com/groups/steamworks/a...</td>\n",
              "      <td>2025</td>\n",
              "      <td>8 ‚Äî 15 December</td>\n",
              "      <td>2025-12-08 00:00:00+00:00</td>\n",
              "      <td>2025-12-15 00:00:00+00:00</td>\n",
              "      <td>fest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Animal Fest</td>\n",
              "      <td>https://steamcommunity.com/groups/steamworks/a...</td>\n",
              "      <td>2025</td>\n",
              "      <td>10 ‚Äî 17 November</td>\n",
              "      <td>2025-11-10 00:00:00+00:00</td>\n",
              "      <td>2025-11-17 00:00:00+00:00</td>\n",
              "      <td>fest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Steam Scream Fest 2025</td>\n",
              "      <td>https://steamcommunity.com/groups/steamworks/a...</td>\n",
              "      <td>2025</td>\n",
              "      <td>27 October ‚Äî 3 November</td>\n",
              "      <td>2025-10-27 00:00:00+00:00</td>\n",
              "      <td>2025-11-03 00:00:00+00:00</td>\n",
              "      <td>fest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Next Fest: October 2025</td>\n",
              "      <td>https://steamcommunity.com/groups/store_promos...</td>\n",
              "      <td>2025</td>\n",
              "      <td>13 ‚Äî 20 October</td>\n",
              "      <td>2025-10-13 00:00:00+00:00</td>\n",
              "      <td>2025-10-20 00:00:00+00:00</td>\n",
              "      <td>fest_next</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Autumn Sale 2025</td>\n",
              "      <td>https://steamcommunity.com/groups/steamworks/a...</td>\n",
              "      <td>2025</td>\n",
              "      <td>29 September ‚Äî 6 October</td>\n",
              "      <td>2025-09-29 00:00:00+00:00</td>\n",
              "      <td>2025-10-06 00:00:00+00:00</td>\n",
              "      <td>seasonal_sale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Political Sim Fest</td>\n",
              "      <td>https://steamcommunity.com/groups/store_promos...</td>\n",
              "      <td>2025</td>\n",
              "      <td>8 ‚Äî 15 September</td>\n",
              "      <td>2025-09-08 00:00:00+00:00</td>\n",
              "      <td>2025-09-15 00:00:00+00:00</td>\n",
              "      <td>fest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Third Person Shooter (TPS) Fest</td>\n",
              "      <td>https://steamcommunity.com/groups/store_promos...</td>\n",
              "      <td>2025</td>\n",
              "      <td>25 August ‚Äî 1 September</td>\n",
              "      <td>2025-08-25 00:00:00+00:00</td>\n",
              "      <td>2025-09-01 00:00:00+00:00</td>\n",
              "      <td>fest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4X Fest</td>\n",
              "      <td>https://steamcommunity.com/groups/store_promos...</td>\n",
              "      <td>2025</td>\n",
              "      <td>11 ‚Äî 18 August</td>\n",
              "      <td>2025-08-11 00:00:00+00:00</td>\n",
              "      <td>2025-08-18 00:00:00+00:00</td>\n",
              "      <td>fest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Racing Fest</td>\n",
              "      <td>https://steamcommunity.com/groups/store_promos...</td>\n",
              "      <td>2025</td>\n",
              "      <td>28 July ‚Äî 4 August</td>\n",
              "      <td>2025-07-28 00:00:00+00:00</td>\n",
              "      <td>2025-08-04 00:00:00+00:00</td>\n",
              "      <td>fest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Automation Fest</td>\n",
              "      <td>https://steamcommunity.com/groups/steamworks/a...</td>\n",
              "      <td>2025</td>\n",
              "      <td>14 ‚Äî 21 July</td>\n",
              "      <td>2025-07-14 00:00:00+00:00</td>\n",
              "      <td>2025-07-21 00:00:00+00:00</td>\n",
              "      <td>fest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Summer Sale 2025</td>\n",
              "      <td>https://steamcommunity.com/games/593110/announ...</td>\n",
              "      <td>2025</td>\n",
              "      <td>26 June ‚Äî 10 July</td>\n",
              "      <td>2025-06-26 00:00:00+00:00</td>\n",
              "      <td>2025-07-10 00:00:00+00:00</td>\n",
              "      <td>seasonal_sale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Fishing Fest</td>\n",
              "      <td>https://steamcommunity.com/games/593110/announ...</td>\n",
              "      <td>2025</td>\n",
              "      <td>16 ‚Äî 23 June</td>\n",
              "      <td>2025-06-16 00:00:00+00:00</td>\n",
              "      <td>2025-06-23 00:00:00+00:00</td>\n",
              "      <td>fest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Next Fest: June 2025</td>\n",
              "      <td>https://steamcommunity.com/games/593110/announ...</td>\n",
              "      <td>2025</td>\n",
              "      <td>9 ‚Äî 16 June</td>\n",
              "      <td>2025-06-09 00:00:00+00:00</td>\n",
              "      <td>2025-06-16 00:00:00+00:00</td>\n",
              "      <td>fest_next</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Zombies vs. Vampires Fest</td>\n",
              "      <td>https://steamcommunity.com/games/593110/announ...</td>\n",
              "      <td>2025</td>\n",
              "      <td>26 May ‚Äî 2 June</td>\n",
              "      <td>2025-05-26 00:00:00+00:00</td>\n",
              "      <td>2025-06-02 00:00:00+00:00</td>\n",
              "      <td>fest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Ocean Fest</td>\n",
              "      <td>https://steamcommunity.com/groups/steamworks/a...</td>\n",
              "      <td>2025</td>\n",
              "      <td>18 ‚Äî 25 May</td>\n",
              "      <td>2025-05-18 00:00:00+00:00</td>\n",
              "      <td>2025-05-25 00:00:00+00:00</td>\n",
              "      <td>fest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Creature Collector Fest</td>\n",
              "      <td>https://steamcommunity.com/games/593110/announ...</td>\n",
              "      <td>2025</td>\n",
              "      <td>12 ‚Äî 19 May</td>\n",
              "      <td>2025-05-12 00:00:00+00:00</td>\n",
              "      <td>2025-05-19 00:00:00+00:00</td>\n",
              "      <td>fest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Deckbuilders Fest</td>\n",
              "      <td>https://steamcommunity.com/groups/steamworks/a...</td>\n",
              "      <td>2025</td>\n",
              "      <td>4 ‚Äî 11 May</td>\n",
              "      <td>2025-05-04 00:00:00+00:00</td>\n",
              "      <td>2025-05-11 00:00:00+00:00</td>\n",
              "      <td>fest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Wargames Fest</td>\n",
              "      <td>https://steamcommunity.com/games/593110/announ...</td>\n",
              "      <td>2025</td>\n",
              "      <td>28 April ‚Äî 5 May</td>\n",
              "      <td>2025-04-28 00:00:00+00:00</td>\n",
              "      <td>2025-05-05 00:00:00+00:00</td>\n",
              "      <td>fest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Box-Pushing (Sokoban) Fest</td>\n",
              "      <td>https://steamcommunity.com/games/593110/announ...</td>\n",
              "      <td>2025</td>\n",
              "      <td>21 ‚Äî 28 April</td>\n",
              "      <td>2025-04-21 00:00:00+00:00</td>\n",
              "      <td>2025-04-28 00:00:00+00:00</td>\n",
              "      <td>fest</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dca8a7f2-c480-4f4b-89fc-2350b091438d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dca8a7f2-c480-4f4b-89fc-2350b091438d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dca8a7f2-c480-4f4b-89fc-2350b091438d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6e950d6d-a763-4282-8f74-8c64f40ee4ca\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6e950d6d-a763-4282-8f74-8c64f40ee4ca')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6e950d6d-a763-4282-8f74-8c64f40ee4ca button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 207,\n  \"fields\": [\n    {\n      \"column\": \"event_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 203,\n        \"samples\": [\n          \"Ocean Fest\",\n          \"Racing Fest\",\n          \"Pirate Sale\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 191,\n        \"samples\": [\n          \"https://twitter.com/steam_games/status/660153014116708352\",\n          \"https://store.steampowered.com/news/app/593110/view/3341121821003187514\",\n          \"https://twitter.com/steam_games/status/565211141970751488\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year_context\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 2007,\n        \"max\": 2025,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          2025,\n          2020,\n          2014\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date_text_raw\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 193,\n        \"samples\": [\n          \"16 \\u2014 23 September\",\n          \"7 \\u2014 8 November\",\n          \"15 \\u2014 22 May\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start_utc\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2007-12-24 00:00:00+00:00\",\n        \"max\": \"2025-12-18 00:00:00+00:00\",\n        \"num_unique_values\": 206,\n        \"samples\": [\n          \"2025-05-18 00:00:00+00:00\",\n          \"2025-07-28 00:00:00+00:00\",\n          \"2009-12-22 00:00:00+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end_utc\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2008-01-01 00:00:00+00:00\",\n        \"max\": \"2026-01-05 00:00:00+00:00\",\n        \"num_unique_values\": 206,\n        \"samples\": [\n          \"2025-05-25 00:00:00+00:00\",\n          \"2025-08-04 00:00:00+00:00\",\n          \"2010-01-03 00:00:00+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"event_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"fest\",\n          \"other\",\n          \"fest_next\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Í≤åÏûÑÎ≥Ñ Ìï†Ïù∏/Í∞ÄÍ≤© ÌûàÏä§ÌÜ†Î¶¨ ÏàòÏßë\n",
        "- ITAD(IsThereAnyDeal) API\n",
        "- Í∞ÄÍ≤©/ÏÑ∏Ïùº ÌûàÏä§ÌÜ†Î¶¨ Ï†ÑÏ≤¥ ÏàòÏßë ÏÇ¨Ïù¥Ìä∏\n",
        "- SHOP_ID = 61 -> Steam Í∞ÄÍ≤© Î≥ÄÎèô ÏßÄÌëúÎßå ÏÇ¨Ïö©\n",
        "- ÏÜçÎèÑ Ìñ•ÏÉÅÏùÑ ÏúÑÌï¥ 50Í∞ú Îã®ÏúÑ append Ï†ÄÏû•\n",
        "- Ï§ëÎã®Ïãú Ïû¨Í∞ú ÏõêÌôúÏùÑ ÏúÑÌï¥ Ï∫êÏãú Ï†ÄÏû•"
      ],
      "metadata": {
        "id": "5K8O4wirnUVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, time, itertools\n",
        "import pandas as pd\n",
        "import requests\n",
        "from urllib3.util.retry import Retry\n",
        "from requests.adapters import HTTPAdapter\n",
        "\n",
        "# ÏÑ§Ï†ï\n",
        "API_KEY   = \"fe20eb4bb09ac4ef74150d90cc0e1e071158508e\"\n",
        "CSV_IN    = \"/content/steam_review_f2p_false.csv\"       # appid Ìè¨Ìï® CSV\n",
        "COUNTRY   = \"US\"\n",
        "SINCE     = \"2019-01-01T00:00:00Z\"\n",
        "SHOP_ID   = 61                                          # Steam\n",
        "OUT_FULL  = \"sales_steam.csv\"\n",
        "CACHE_FILE= \"itad_cache.json\"\n",
        "DONE_FILE = \"processed_appids.json\"\n",
        "SAVE_EVERY= 50\n",
        "SLEEP_SEC = 0.5\n",
        "\n",
        "# HTTP ÏÑ∏ÏÖò\n",
        "def make_session():\n",
        "    s = requests.Session()\n",
        "    retries = Retry(\n",
        "        total=5, backoff_factor=0.6,\n",
        "        status_forcelist=(429,500,502,503,504),\n",
        "        allowed_methods=[\"GET\",\"POST\"]\n",
        "    )\n",
        "    s.headers.update({\"User-Agent\":\"itad-batch/1.2\"})\n",
        "    s.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
        "    return s\n",
        "session = make_session()\n",
        "\n",
        "# Ïú†Ìã∏ Ìï®Ïàò ÏûëÏÑ±\n",
        "def chunked(it, n):\n",
        "    it = iter(it)\n",
        "    while True:\n",
        "        batch = list(itertools.islice(it, n))\n",
        "        if not batch: break\n",
        "        yield batch\n",
        "\n",
        "def load_json(path, default):\n",
        "    if os.path.exists(path):\n",
        "        try:\n",
        "            return json.load(open(path, \"r\"))\n",
        "        except:\n",
        "            return default\n",
        "    return default\n",
        "\n",
        "def save_json(path, obj):\n",
        "    tmp = path + \".tmp\"\n",
        "    with open(tmp, \"w\") as f:\n",
        "        json.dump(obj, f)\n",
        "    os.replace(tmp, path)\n",
        "\n",
        "# ITAD API\n",
        "def lookup_batch(appids):\n",
        "    url = f\"https://api.isthereanydeal.com/lookup/id/shop/{SHOP_ID}/v1\"\n",
        "    body = [f\"app/{a}\" for a in appids]\n",
        "    r = session.post(url, params={\"key\": API_KEY}, json=body, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    data = r.json()\n",
        "    return {int(k.split(\"/\")[1]): v for k,v in data.items()}\n",
        "\n",
        "def fetch_history(itad_id, country=COUNTRY, since=SINCE):\n",
        "    url = \"https://api.isthereanydeal.com/games/history/v2\"\n",
        "    params = {\"key\": API_KEY, \"id\": itad_id, \"country\": country}\n",
        "    if since: params[\"since\"] = since\n",
        "    r = session.get(url, params=params, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    data = r.json()\n",
        "    if isinstance(data, dict) and \"history\" in data:\n",
        "        data = data[\"history\"]\n",
        "    return data if isinstance(data, list) else []\n",
        "\n",
        "# ÌååÏÑú (Í∞ÄÍ≤© Ïä§ÏºÄÏùº ÌîΩÏä§)\n",
        "def parse_history_item(item):\n",
        "    shop = item.get(\"shop\", {})\n",
        "    if not isinstance(shop, dict) or shop.get(\"id\") != SHOP_ID:\n",
        "        return None\n",
        "\n",
        "    deal = item.get(\"deal\", {})\n",
        "    if not isinstance(deal, dict):\n",
        "        return None\n",
        "\n",
        "    price_obj = deal.get(\"price\")\n",
        "    price_raw = None\n",
        "    price_major = None\n",
        "    currency = None\n",
        "\n",
        "    if isinstance(price_obj, dict):\n",
        "        amount = price_obj.get(\"amount\")\n",
        "        currency = price_obj.get(\"currency\")\n",
        "        price_raw = amount\n",
        "        if isinstance(amount, int):\n",
        "            price_major = amount / 100.0\n",
        "        elif isinstance(amount, float):\n",
        "            price_major = float(amount)\n",
        "\n",
        "    cut = deal.get(\"cut\")\n",
        "\n",
        "    return {\n",
        "        \"timestamp\": item.get(\"timestamp\"),\n",
        "        \"price_raw\": price_raw,\n",
        "        \"price\": price_major,\n",
        "        \"currency\": currency,\n",
        "        \"cut\": cut,\n",
        "        \"shop_id\": shop.get(\"id\"),\n",
        "        \"shop\": shop.get(\"name\"),\n",
        "    }\n",
        "\n",
        "# ÏûÖÎ†• appid\n",
        "df_in = pd.read_csv(CSV_IN)\n",
        "all_appids = pd.Index(df_in[\"appid\"].dropna().astype(int).unique()).tolist()\n",
        "print(f\"Ï¥ù appid: {len(all_appids)}\")\n",
        "\n",
        "# Ï∫êÏãú/Ïû¨Í∞ú\n",
        "cache = load_json(CACHE_FILE, {})\n",
        "done  = set(load_json(DONE_FILE, []))\n",
        "\n",
        "if os.path.exists(OUT_FULL):\n",
        "    try:\n",
        "        prev = pd.read_csv(OUT_FULL, usecols=[\"appid\"])\n",
        "        done |= set(prev[\"appid\"].astype(int).unique().tolist())\n",
        "    except Exception as e:\n",
        "        print(\"[WARN] Í∏∞Ï°¥ sales_steam.csv ÏùΩÍ∏∞ Ïã§Ìå®:\", e)\n",
        "\n",
        "todo_appids = [a for a in all_appids if a not in done]\n",
        "print(f\"Ï≤òÎ¶¨ ÎåÄÏÉÅ: {len(todo_appids)}Í∞ú / Ïù¥ÎØ∏ ÏôÑÎ£å: {len(done)}Í∞ú\")\n",
        "\n",
        "# appid -> itad_id Îß§Ìïë ÏÑ†Ï°∞Ìöå\n",
        "missing = [a for a in todo_appids if str(a) not in cache]\n",
        "for batch in chunked(missing, 100):\n",
        "    try:\n",
        "        res = lookup_batch(batch)\n",
        "        for a in batch:\n",
        "            cache[str(a)] = res.get(a)\n",
        "        save_json(CACHE_FILE, cache)\n",
        "        time.sleep(SLEEP_SEC)\n",
        "    except requests.HTTPError as e:\n",
        "        print(f\"[LOOKUP ERR] size={len(batch)} -> {e}\")\n",
        "        time.sleep(SLEEP_SEC*3)\n",
        "\n",
        "# ÌûàÏä§ÌÜ†Î¶¨ ÏàòÏßë\n",
        "buffer, processed = [], 0\n",
        "total = len(todo_appids)\n",
        "\n",
        "def append_csv(rows):\n",
        "    df = pd.DataFrame.from_records(rows)\n",
        "    header = not os.path.exists(OUT_FULL)\n",
        "    df.to_csv(OUT_FULL, mode=\"a\", index=False, header=header)\n",
        "\n",
        "for i, appid in enumerate(todo_appids, 1):\n",
        "    itad_id = cache.get(str(appid))\n",
        "    if not itad_id:\n",
        "        done.add(appid)\n",
        "        if i % SAVE_EVERY == 0: save_json(DONE_FILE, sorted(list(done)))\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        hist = fetch_history(itad_id)\n",
        "        kept = 0\n",
        "        for h in hist:\n",
        "            parsed = parse_history_item(h)\n",
        "            if parsed:\n",
        "                parsed[\"appid\"] = appid\n",
        "                parsed[\"itad_id\"] = itad_id\n",
        "                buffer.append(parsed)\n",
        "                kept += 1\n",
        "\n",
        "        done.add(appid)\n",
        "        processed += 1\n",
        "\n",
        "        if i % 50 == 0 or i == total:\n",
        "            print(f\"[{i}/{total}] appid {appid} -> kept {kept} (Î≤ÑÌçº {len(buffer)})\")\n",
        "\n",
        "        if processed >= SAVE_EVERY or len(buffer) >= 5000:\n",
        "            if buffer:\n",
        "                append_csv(buffer); buffer.clear()\n",
        "            save_json(DONE_FILE, sorted(list(done)))\n",
        "            save_json(CACHE_FILE, cache)\n",
        "            processed = 0\n",
        "\n",
        "        time.sleep(SLEEP_SEC)\n",
        "\n",
        "    except requests.HTTPError as e:\n",
        "        print(f\"[HIST ERR] appid {appid} ({itad_id}) -> {e}\")\n",
        "        time.sleep(SLEEP_SEC*4)\n",
        "    except Exception as e:\n",
        "        print(f\"[ERR] appid {appid}: {e}\")\n",
        "        time.sleep(SLEEP_SEC*2)\n",
        "\n",
        "# ÎÇ®ÏùÄ Î≤ÑÌçº flush\n",
        "if buffer:\n",
        "    append_csv(buffer)\n",
        "save_json(DONE_FILE, sorted(list(done)))\n",
        "save_json(CACHE_FILE, cache)\n",
        "print(f\"ÏôÑÎ£å ‚úÖ (Ï∂úÎ†•: {OUT_FULL})\")\n",
        "\n",
        "# ÏÑ∏Ïùº Íµ¨Í∞Ñ ÏöîÏïΩ\n",
        "print(\"ÏÑ∏Ïùº Íµ¨Í∞Ñ ÏöîÏïΩ ÏÉùÏÑ± Ï§ë...\")\n",
        "df_all = pd.read_csv(OUT_FULL)\n",
        "if not df_all.empty:\n",
        "    dfx = df_all.copy()\n",
        "    dfx[\"ts\"] = pd.to_datetime(dfx[\"timestamp\"], utc=True, errors=\"coerce\")\n",
        "    dfx = dfx.dropna(subset=[\"ts\"]).sort_values([\"appid\",\"ts\"])\n",
        "    dfx[\"on_sale\"] = dfx[\"cut\"].fillna(0).astype(float) > 0\n",
        "    dfx[\"boundary\"] = dfx.groupby(\"appid\")[\"on_sale\"].apply(lambda s: s.ne(s.shift(1))).reset_index(drop=True)\n",
        "    dfx[\"block\"] = dfx.groupby(\"appid\")[\"boundary\"].cumsum()\n",
        "\n",
        "    sale_blocks = []\n",
        "    for (appid, block), g in dfx.groupby([\"appid\",\"block\"]):\n",
        "        if not g[\"on_sale\"].iloc[0]:\n",
        "            continue\n",
        "        sale_blocks.append({\n",
        "            \"appid\": appid,\n",
        "            \"sale_start_utc\": g[\"ts\"].iloc[0],\n",
        "            \"sale_end_utc\": g[\"ts\"].iloc[-1],\n",
        "            \"discount_max\": g[\"cut\"].max(),\n",
        "            \"n_points\": len(g)\n",
        "        })\n",
        "    sale_df = pd.DataFrame(sale_blocks).sort_values([\"appid\",\"sale_start_utc\"])\n",
        "    sale_out = \"sale_periods.csv\"\n",
        "    sale_df.to_csv(sale_out, index=False)\n",
        "    print(f\"ÏÑ∏Ïùº ÏöîÏïΩ Ï†ÄÏû• ‚Üí {sale_out}  (rows={len(sale_df)})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4BNlCP3nODg",
        "outputId": "d258bb95-3c67-4739-cc0e-04a5b8bf5588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ï¥ù appid: 6653\n",
            "Ï≤òÎ¶¨ ÎåÄÏÉÅ: 6653Í∞ú / Ïù¥ÎØ∏ ÏôÑÎ£å: 0Í∞ú\n",
            "[50/6653] appid 1008230 -> kept 43 (Î≤ÑÌçº 3499)\n",
            "[100/6653] appid 1016360 -> kept 48 (Î≤ÑÌçº 4256)\n",
            "[150/6653] appid 1023870 -> kept 23 (Î≤ÑÌçº 3565)\n",
            "[200/6653] appid 1045520 -> kept 100 (Î≤ÑÌçº 3647)\n",
            "[250/6653] appid 1054990 -> kept 72 (Î≤ÑÌçº 3541)\n",
            "[300/6653] appid 1061100 -> kept 7 (Î≤ÑÌçº 3361)\n",
            "[350/6653] appid 1066900 -> kept 54 (Î≤ÑÌçº 3271)\n",
            "[400/6653] appid 1087760 -> kept 60 (Î≤ÑÌçº 3457)\n",
            "[450/6653] appid 1094930 -> kept 100 (Î≤ÑÌçº 3517)\n",
            "[500/6653] appid 1101140 -> kept 131 (Î≤ÑÌçº 3006)\n",
            "[550/6653] appid 110800 -> kept 108 (Î≤ÑÌçº 3569)\n",
            "[600/6653] appid 1116210 -> kept 112 (Î≤ÑÌçº 3346)\n",
            "[650/6653] appid 1137350 -> kept 65 (Î≤ÑÌçº 3572)\n",
            "[700/6653] appid 1144440 -> kept 22 (Î≤ÑÌçº 3375)\n",
            "[750/6653] appid 1150590 -> kept 27 (Î≤ÑÌçº 3593)\n",
            "[800/6653] appid 1157220 -> kept 57 (Î≤ÑÌçº 3586)\n",
            "[850/6653] appid 1175480 -> kept 37 (Î≤ÑÌçº 3489)\n",
            "[900/6653] appid 1183470 -> kept 105 (Î≤ÑÌçº 3393)\n",
            "[950/6653] appid 1192440 -> kept 31 (Î≤ÑÌçº 3075)\n",
            "[1000/6653] appid 1200910 -> kept 114 (Î≤ÑÌçº 2934)\n",
            "[1050/6653] appid 1222700 -> kept 85 (Î≤ÑÌçº 3271)\n",
            "[1100/6653] appid 1230530 -> kept 22 (Î≤ÑÌçº 3034)\n",
            "[1150/6653] appid 1238020 -> kept 38 (Î≤ÑÌçº 3194)\n",
            "[1200/6653] appid 1260810 -> kept 97 (Î≤ÑÌçº 3273)\n",
            "[1250/6653] appid 1267540 -> kept 64 (Î≤ÑÌçº 2574)\n",
            "[1300/6653] appid 1276330 -> kept 105 (Î≤ÑÌçº 3174)\n",
            "[1350/6653] appid 1285560 -> kept 108 (Î≤ÑÌçº 3141)\n",
            "[1400/6653] appid 1308950 -> kept 116 (Î≤ÑÌçº 3234)\n",
            "[1450/6653] appid 1322170 -> kept 101 (Î≤ÑÌçº 2828)\n",
            "[1500/6653] appid 1333360 -> kept 10 (Î≤ÑÌçº 3235)\n",
            "[1550/6653] appid 1342040 -> kept 92 (Î≤ÑÌçº 3147)\n",
            "[1600/6653] appid 1364180 -> kept 2 (Î≤ÑÌçº 2609)\n",
            "[1650/6653] appid 1374740 -> kept 61 (Î≤ÑÌçº 2797)\n",
            "[1700/6653] appid 1385100 -> kept 74 (Î≤ÑÌçº 2654)\n",
            "[1750/6653] appid 1394800 -> kept 82 (Î≤ÑÌçº 2968)\n",
            "[1800/6653] appid 1423330 -> kept 0 (Î≤ÑÌçº 2680)\n",
            "[1850/6653] appid 1433140 -> kept 29 (Î≤ÑÌçº 2561)\n",
            "[1900/6653] appid 1446330 -> kept 99 (Î≤ÑÌçº 2582)\n",
            "[1950/6653] appid 1455840 -> kept 83 (Î≤ÑÌçº 2400)\n",
            "[2000/6653] appid 1487590 -> kept 46 (Î≤ÑÌçº 2278)\n",
            "[2050/6653] appid 1499300 -> kept 6 (Î≤ÑÌçº 2588)\n",
            "[2100/6653] appid 1509230 -> kept 97 (Î≤ÑÌçº 2562)\n",
            "[2150/6653] appid 1520090 -> kept 49 (Î≤ÑÌçº 2600)\n",
            "[2200/6653] appid 1549970 -> kept 86 (Î≤ÑÌçº 2567)\n",
            "[2250/6653] appid 1561470 -> kept 4 (Î≤ÑÌçº 2745)\n",
            "[2300/6653] appid 1571170 -> kept 0 (Î≤ÑÌçº 2147)\n",
            "[2350/6653] appid 1580240 -> kept 46 (Î≤ÑÌçº 2674)\n",
            "[2400/6653] appid 1607310 -> kept 14 (Î≤ÑÌçº 2449)\n",
            "[2450/6653] appid 1620890 -> kept 82 (Î≤ÑÌçº 2487)\n",
            "[2500/6653] appid 1636420 -> kept 84 (Î≤ÑÌçº 2251)\n",
            "[2550/6653] appid 1650020 -> kept 28 (Î≤ÑÌçº 2203)\n",
            "[2600/6653] appid 1687550 -> kept 53 (Î≤ÑÌçº 2312)\n",
            "[2650/6653] appid 1706850 -> kept 41 (Î≤ÑÌçº 1896)\n",
            "[2700/6653] appid 1722760 -> kept 61 (Î≤ÑÌçº 2154)\n",
            "[2750/6653] appid 1736400 -> kept 0 (Î≤ÑÌçº 2192)\n",
            "[2800/6653] appid 1780370 -> kept 26 (Î≤ÑÌçº 2458)\n",
            "[2850/6653] appid 1797300 -> kept 84 (Î≤ÑÌçº 2080)\n",
            "[2900/6653] appid 1812930 -> kept 7 (Î≤ÑÌçº 1900)\n",
            "[2950/6653] appid 1829980 -> kept 48 (Î≤ÑÌçº 1840)\n",
            "[3000/6653] appid 1879380 -> kept 36 (Î≤ÑÌçº 1821)\n",
            "[3050/6653] appid 1898430 -> kept 0 (Î≤ÑÌçº 1880)\n",
            "[3100/6653] appid 1916270 -> kept 69 (Î≤ÑÌçº 1884)\n",
            "[3150/6653] appid 1929870 -> kept 42 (Î≤ÑÌçº 2157)\n",
            "[3200/6653] appid 19680 -> kept 55 (Î≤ÑÌçº 2169)\n",
            "[3250/6653] appid 1988540 -> kept 27 (Î≤ÑÌçº 2058)\n",
            "[3300/6653] appid 2009100 -> kept 38 (Î≤ÑÌçº 2356)\n",
            "[3350/6653] appid 2072890 -> kept 0 (Î≤ÑÌçº 2228)\n",
            "[3400/6653] appid 2090150 -> kept 65 (Î≤ÑÌçº 2292)\n",
            "[3450/6653] appid 2108330 -> kept 10 (Î≤ÑÌçº 1970)\n",
            "[3500/6653] appid 2124780 -> kept 26 (Î≤ÑÌçº 2204)\n",
            "[3550/6653] appid 2183650 -> kept 34 (Î≤ÑÌçº 2195)\n",
            "[3600/6653] appid 220460 -> kept 90 (Î≤ÑÌçº 2750)\n",
            "[3650/6653] appid 22230 -> kept 56 (Î≤ÑÌçº 2341)\n",
            "[3700/6653] appid 2239550 -> kept 54 (Î≤ÑÌçº 2904)\n",
            "[3750/6653] appid 230070 -> kept 115 (Î≤ÑÌçº 2118)\n",
            "[3800/6653] appid 2328750 -> kept 38 (Î≤ÑÌçº 2596)\n",
            "[3850/6653] appid 2351970 -> kept 22 (Î≤ÑÌçº 2705)\n",
            "[3900/6653] appid 2383760 -> kept 43 (Î≤ÑÌçº 2936)\n",
            "[3950/6653] appid 24790 -> kept 54 (Î≤ÑÌçº 2689)\n",
            "[4000/6653] appid 251990 -> kept 130 (Î≤ÑÌçº 3089)\n",
            "[4050/6653] appid 256290 -> kept 111 (Î≤ÑÌçº 2879)\n",
            "[4100/6653] appid 265550 -> kept 113 (Î≤ÑÌçº 3993)\n",
            "[4150/6653] appid 292500 -> kept 132 (Î≤ÑÌçº 4368)\n",
            "[4200/6653] appid 305380 -> kept 90 (Î≤ÑÌçº 4543)\n",
            "[4250/6653] appid 313780 -> kept 152 (Î≤ÑÌçº 4267)\n",
            "[4300/6653] appid 32430 -> kept 74 (Î≤ÑÌçº 4163)\n",
            "[4350/6653] appid 345890 -> kept 48 (Î≤ÑÌçº 4215)\n",
            "[4400/6653] appid 354240 -> kept 107 (Î≤ÑÌçº 4454)\n",
            "[4450/6653] appid 362930 -> kept 137 (Î≤ÑÌçº 4516)\n",
            "[4500/6653] appid 371520 -> kept 138 (Î≤ÑÌçº 4462)\n",
            "[4550/6653] appid 39540 -> kept 100 (Î≤ÑÌçº 4570)\n",
            "[4600/6653] appid 403780 -> kept 158 (Î≤ÑÌçº 4687)\n",
            "[4650/6653] appid 411830 -> kept 87 (Î≤ÑÌçº 4594)\n",
            "[4700/6653] appid 422970 -> kept 90 (Î≤ÑÌçº 4768)\n",
            "[4750/6653] appid 449550 -> kept 69 (Î≤ÑÌçº 4451)\n",
            "[4800/6653] appid 462100 -> kept 60 (Î≤ÑÌçº 4228)\n",
            "[4850/6653] appid 47400 -> kept 134 (Î≤ÑÌçº 4610)\n",
            "[4900/6653] appid 48700 -> kept 87 (Î≤ÑÌçº 3737)\n",
            "[4950/6653] appid 513880 -> kept 145 (Î≤ÑÌçº 4184)\n",
            "[5000/6653] appid 525700 -> kept 94 (Î≤ÑÌçº 3996)\n",
            "[5050/6653] appid 538840 -> kept 100 (Î≤ÑÌçº 4152)\n",
            "[5100/6653] appid 570780 -> kept 92 (Î≤ÑÌçº 4348)\n",
            "[5150/6653] appid 581320 -> kept 131 (Î≤ÑÌçº 4473)\n",
            "[5200/6653] appid 590380 -> kept 98 (Î≤ÑÌçº 4299)\n",
            "[5250/6653] appid 6000 -> kept 66 (Î≤ÑÌçº 4117)\n",
            "[5300/6653] appid 623080 -> kept 90 (Î≤ÑÌçº 4168)\n",
            "[5350/6653] appid 633360 -> kept 86 (Î≤ÑÌçº 4304)\n",
            "[5400/6653] appid 644550 -> kept 37 (Î≤ÑÌçº 4375)\n",
            "[5450/6653] appid 655420 -> kept 8 (Î≤ÑÌçº 4415)\n",
            "[5500/6653] appid 680830 -> kept 23 (Î≤ÑÌçº 4306)\n",
            "[5550/6653] appid 690530 -> kept 31 (Î≤ÑÌçº 4146)\n",
            "[5600/6653] appid 700600 -> kept 54 (Î≤ÑÌçº 4609)\n",
            "[5650/6653] appid 71250 -> kept 88 (Î≤ÑÌçº 4738)\n",
            "[5700/6653] appid 743640 -> kept 150 (Î≤ÑÌçº 3799)\n",
            "[5750/6653] appid 752580 -> kept 0 (Î≤ÑÌçº 3927)\n",
            "[5800/6653] appid 761830 -> kept 92 (Î≤ÑÌçº 4678)\n",
            "[5850/6653] appid 773840 -> kept 43 (Î≤ÑÌçº 3939)\n",
            "[5900/6653] appid 799070 -> kept 15 (Î≤ÑÌçº 4433)\n",
            "[5950/6653] appid 809770 -> kept 50 (Î≤ÑÌçº 4150)\n",
            "[6000/6653] appid 820900 -> kept 118 (Î≤ÑÌçº 4586)\n",
            "[6050/6653] appid 833910 -> kept 31 (Î≤ÑÌçº 3935)\n",
            "[6100/6653] appid 859340 -> kept 137 (Î≤ÑÌçº 4097)\n",
            "[6150/6653] appid 868980 -> kept 72 (Î≤ÑÌçº 4491)\n",
            "[6200/6653] appid 881560 -> kept 72 (Î≤ÑÌçº 4121)\n",
            "[6250/6653] appid 890720 -> kept 109 (Î≤ÑÌçº 4029)\n",
            "[6300/6653] appid 916730 -> kept 105 (Î≤ÑÌçº 4646)\n",
            "[6350/6653] appid 925940 -> kept 62 (Î≤ÑÌçº 3929)\n",
            "[6400/6653] appid 935570 -> kept 107 (Î≤ÑÌçº 3760)\n",
            "[6450/6653] appid 944050 -> kept 73 (Î≤ÑÌçº 3985)\n",
            "[6500/6653] appid 963450 -> kept 59 (Î≤ÑÌçº 4234)\n",
            "[6550/6653] appid 970570 -> kept 82 (Î≤ÑÌçº 3785)\n",
            "[6600/6653] appid 977500 -> kept 143 (Î≤ÑÌçº 3980)\n",
            "[6650/6653] appid 984800 -> kept 121 (Î≤ÑÌçº 4208)\n",
            "[6653/6653] appid 996580 -> kept 99 (Î≤ÑÌçº 315)\n",
            "ÏôÑÎ£å ‚úÖ (Ï∂úÎ†•: sales_steam.csv)\n",
            "ÏÑ∏Ïùº Íµ¨Í∞Ñ ÏöîÏïΩ ÏÉùÏÑ± Ï§ë...\n",
            "ÏÑ∏Ïùº ÏöîÏïΩ Ï†ÄÏû• ‚Üí sale_periods.csv  (rows=219099)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Î¶¨Î∑∞ √ó ÏÑ∏Ïùº/Ïù¥Î≤§Ìä∏ Ï°∞Ïù∏\n",
        "- reviews_with_sale_flags.csv\n",
        "    - steam_review_f2p_false.csvÏùò Î¶¨Î∑∞(appid, timestamp_created)Î•º Í∏∞Ï§ÄÏúºÎ°ú sale_periods.csv (Í≤åÏûÑ ÏûêÏ≤¥ ÏÑ∏Ïùº Íµ¨Í∞Ñ) steamdb_valve_events_history.csv (Ïä§ÌåÄ Ï£ºÏµú Ïù¥Î≤§Ìä∏ Íµ¨Í∞Ñ) Îß§Ïπ≠ÏãúÌÇ¥\n",
        "    - ÏÑ∏Ïùº/Ïù¥Î≤§Ìä∏ Ïó¨Î∂Ä ÌîåÎûòÍ∑∏Îßå Ìè¨Ìï®\n",
        "\n",
        "- reviews_with_sale_flags_full.csv\n",
        "    - reviews_with_sale_flags.csvÏôÄ ÏõêÎ≥∏ Î¶¨Î∑∞ Îç∞Ïù¥ÌÑ∞ steam_review_f2p_false.csvÎ•º appid + timestamp_created Í∏∞Ï§ÄÏúºÎ°ú Ï°∞Ïù∏\n",
        "    - Î¶¨Î∑∞ Ï†ïÎ≥¥ + ÏÑ∏Ïùº/Ïù¥Î≤§Ìä∏ Ï†ïÎ≥¥ ÌÜµÌï© ÏµúÏ¢Ö Î∂ÑÏÑù Îç∞Ïù¥ÌÑ∞ÏÖã\n",
        "    - Ï§ëÎ≥µÌÇ§ 12Í±¥ ÏûàÏóàÏúºÎÇò Ï†ÑÏ≤¥Ïùò 0.01%ÎèÑ ÎêòÏßÄÏïäÏïÑ Í∑∏ÎÉ• dropÌï¥ ÌïúÏ™ΩÎßå ÎÇ®ÍπÄ"
      ],
      "metadata": {
        "id": "7zOPpqbv0lGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
        "REVIEWS_CSV   = \"/content/steam_review_f2p_false.csv\"\n",
        "SALE_PERIODS  = \"/content/sale_periods.csv\"\n",
        "VALVE_EVENTS  = \"/content/steamdb_valve_events_history.csv\"\n",
        "OUT_CSV       = \"/content/reviews_with_sale_flags.csv\"\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
        "df = pd.read_csv(REVIEWS_CSV)\n",
        "sp = pd.read_csv(SALE_PERIODS)\n",
        "ve = pd.read_csv(VALVE_EVENTS)\n",
        "\n",
        "# Î¶¨Î∑∞: ÌïÑÏàò Ïª¨Îüº ÌôïÏù∏\n",
        "assert \"appid\" in df.columns, \"reviews CSVÏóê appid Ïª¨ÎüºÏù¥ ÌïÑÏöîÌï©ÎãàÎã§.\"\n",
        "assert \"timestamp_created\" in df.columns, \"reviews CSVÏóê timestamp_created Ïª¨ÎüºÏù¥ ÌïÑÏöîÌï©ÎãàÎã§.\"\n",
        "\n",
        "# Ïù¥Î≤§Ìä∏: ÏÇ¨Ïö©ÏûêÍ∞Ä Î≥¥Ïó¨Ï§Ä Ïª¨ÎüºÏóê ÎßûÏ∂∞ Î¶¨ÎÑ§ÏûÑ (start_utc/end_utc ‚Üí event_start_utc/event_end_utc)\n",
        "rename_map = {}\n",
        "if \"start_utc\" in ve.columns: rename_map[\"start_utc\"] = \"event_start_utc\"\n",
        "if \"end_utc\"   in ve.columns: rename_map[\"end_utc\"]   = \"event_end_utc\"\n",
        "ve = ve.rename(columns=rename_map)\n",
        "\n",
        "# ÏÑ∏Ïùº ÏöîÏïΩ: ÌïÑÏàò Ïª¨Îüº ÌôïÏù∏\n",
        "for col in [\"appid\", \"sale_start_utc\", \"sale_end_utc\"]:\n",
        "    assert col in sp.columns, f\"sale_periods CSVÏóê {col} Ïª¨ÎüºÏù¥ ÌïÑÏöîÌï©ÎãàÎã§.\"\n",
        "\n",
        "# Ïù¥Î≤§Ìä∏: ÌïÑÏàò Ïª¨Îüº ÌôïÏù∏\n",
        "for col in [\"event_start_utc\", \"event_end_utc\"]:\n",
        "    assert col in ve.columns, f\"valve_events CSVÏóê {col} Ïª¨ÎüºÏù¥ ÌïÑÏöîÌï©ÎãàÎã§.\"\n",
        "\n",
        "# ÏãúÍ∞Ñ Ï†ïÍ∑úÌôî(UTC)\n",
        "df[\"ts\"] = pd.to_datetime(df[\"timestamp_created\"], utc=True, errors=\"coerce\")\n",
        "sp[\"sale_start_utc\"]   = pd.to_datetime(sp[\"sale_start_utc\"],   utc=True, errors=\"coerce\")\n",
        "sp[\"sale_end_utc\"]     = pd.to_datetime(sp[\"sale_end_utc\"],     utc=True, errors=\"coerce\")\n",
        "ve[\"event_start_utc\"]  = pd.to_datetime(ve[\"event_start_utc\"],  utc=True, errors=\"coerce\")\n",
        "ve[\"event_end_utc\"]    = pd.to_datetime(ve[\"event_end_utc\"],    utc=True, errors=\"coerce\")\n",
        "\n",
        "# Í≤∞Ï∏° Ï†úÍ±∞ & Ï†ïÎ†¨\n",
        "df = df.dropna(subset=[\"appid\", \"ts\"]).sort_values([\"appid\", \"ts\"]).reset_index(drop=True)\n",
        "sp = sp.dropna(subset=[\"appid\", \"sale_start_utc\", \"sale_end_utc\"]).sort_values([\"appid\", \"sale_start_utc\"])\n",
        "ve = ve.dropna(subset=[\"event_start_utc\", \"event_end_utc\"]).sort_values(\"event_start_utc\")\n",
        "\n",
        "# Í≤åÏûÑ ÏûêÏ≤¥ ÏÑ∏Ïùº Îß§Ïπ≠ (appid Í∑∏Î£πÎ≥Ñ)\n",
        "def asof_join_game_sale(group_df):\n",
        "    a = group_df.sort_values(\"ts\")\n",
        "    b = sp[sp[\"appid\"] == group_df.name].sort_values(\"sale_start_utc\")\n",
        "    if b.empty:\n",
        "        a[\"sale_start_utc\"] = pd.NaT\n",
        "        a[\"sale_end_utc\"]   = pd.NaT\n",
        "        a[\"discount_max\"]   = np.nan\n",
        "        return a\n",
        "    merged = pd.merge_asof(\n",
        "        a,\n",
        "        b[[\"sale_start_utc\", \"sale_end_utc\", \"discount_max\"]],\n",
        "        left_on=\"ts\", right_on=\"sale_start_utc\",\n",
        "        direction=\"backward\",\n",
        "    )\n",
        "    return merged\n",
        "\n",
        "df = df.groupby(\"appid\", group_keys=False).apply(asof_join_game_sale)\n",
        "\n",
        "# Ìè¨Ìï® Ïó¨Î∂Ä ÌîåÎûòÍ∑∏ (Î¶¨Î∑∞ ÏãúÏ†êÏù¥ sale_end Ïù¥Ìïò)\n",
        "df[\"on_game_sale\"] = (df[\"ts\"] <= df[\"sale_end_utc\"]).fillna(False)\n",
        "\n",
        "# Ïä§ÌåÄ Ï£ºÏµú Ïù¥Î≤§Ìä∏ Îß§Ïπ≠\n",
        "df = df.sort_values(\"ts\")\n",
        "df = pd.merge_asof(\n",
        "    df,\n",
        "    ve[[\"event_start_utc\", \"event_end_utc\", \"event_name\", \"event_type\"]] if \"event_name\" in ve.columns else ve[[\"event_start_utc\", \"event_end_utc\"]],\n",
        "    left_on=\"ts\", right_on=\"event_start_utc\",\n",
        "    direction=\"backward\",\n",
        ")\n",
        "df[\"on_valve_event\"] = (df[\"ts\"] <= df[\"event_end_utc\"]).fillna(False)\n",
        "\n",
        "# Ïª®ÌÖçÏä§Ìä∏ ÎùºÎ≤®\n",
        "def _ctx(row):\n",
        "    g, v = bool(row[\"on_game_sale\"]), bool(row[\"on_valve_event\"])\n",
        "    if g and v: return \"both\"\n",
        "    if g and not v: return \"game_only\"\n",
        "    if (not g) and v: return \"event_only\"\n",
        "    return \"none\"\n",
        "\n",
        "df[\"sale_context\"] = df.apply(_ctx, axis=1)\n",
        "\n",
        "# Ï†ÄÏû•\n",
        "keep_cols = [\n",
        "    \"appid\", \"timestamp_created\", \"ts\",\n",
        "    \"on_game_sale\", \"discount_max\", \"sale_start_utc\", \"sale_end_utc\",\n",
        "    \"on_valve_event\", \"event_start_utc\", \"event_end_utc\", \"sale_context\"\n",
        "]\n",
        "# Ïù¥Î≤§Ìä∏ Î©îÌÉÄÍ∞Ä ÏûàÏúºÎ©¥ Ìè¨Ìï®\n",
        "for meta_col in [\"event_name\", \"event_type\"]:\n",
        "    if meta_col in df.columns:\n",
        "        keep_cols.append(meta_col)\n",
        "\n",
        "keep_cols = [c for c in keep_cols if c in df.columns]\n",
        "df_out = df[keep_cols].copy()\n",
        "df_out.to_csv(OUT_CSV, index=False)\n",
        "\n",
        "# ÏöîÏïΩ Ï∂úÎ†•\n",
        "print(\"Saved ->\", OUT_CSV)\n",
        "print(df_out[\"sale_context\"].value_counts(dropna=False).to_string())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km66APlo01Mt",
        "outputId": "3649c8fd-74fa-4f30-a2ce-697dfa2a2bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4017389642.py:62: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df = df.groupby(\"appid\", group_keys=False).apply(asof_join_game_sale)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved -> /content/reviews_with_sale_flags.csv\n",
            "sale_context\n",
            "none          68848\n",
            "event_only    34970\n",
            "both            226\n",
            "game_only       223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Í≤ΩÎ°ú\n",
        "REVIEWS_CSV = \"/content/steam_review_f2p_false.csv\"\n",
        "FLAGS_CSV   = \"/content/reviews_with_sale_flags.csv\"\n",
        "OUT_CSV     = \"/content/reviews_with_sale_flags_full.csv\"\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
        "df_reviews = pd.read_csv(REVIEWS_CSV)\n",
        "df_flags   = pd.read_csv(FLAGS_CSV)\n",
        "\n",
        "# datetime Î≥ÄÌôò\n",
        "df_reviews[\"timestamp_created\"] = pd.to_datetime(\n",
        "    df_reviews[\"timestamp_created\"], utc=True, errors=\"coerce\"\n",
        ")\n",
        "df_flags[\"timestamp_created\"] = pd.to_datetime(\n",
        "    df_flags[\"timestamp_created\"], utc=True, errors=\"coerce\"\n",
        ")\n",
        "\n",
        "# Î≥ëÌï©\n",
        "df_merged = pd.merge(\n",
        "    df_reviews,\n",
        "    df_flags,\n",
        "    on=[\"appid\", \"timestamp_created\"],\n",
        "    how=\"inner\"\n",
        ")\n",
        "\n",
        "# Ï§ëÎ≥µ Ï≤¥ÌÅ¨\n",
        "dupe_mask = df_merged.duplicated(subset=[\"appid\",\"timestamp_created\"], keep=False)\n",
        "n_dupes = dupe_mask.sum()\n",
        "\n",
        "if n_dupes > 0:\n",
        "    print(f\"[Í≤ΩÍ≥†] Ï§ëÎ≥µÎêú Îß§Ïπ≠ {n_dupes}Í±¥ Î∞úÍ≤¨ (appid+timestamp_created Í∏∞Ï§Ä).\")\n",
        "    # Ï§ëÎ≥µÎêú Ìñâ ÎØ∏Î¶¨Î≥¥Í∏∞\n",
        "    print(df_merged.loc[dupe_mask, [\"appid\",\"timestamp_created\"]].head(10))\n",
        "\n",
        "    # ÌïÑÏöîÌïòÎ©¥ Ïó¨Í∏∞ÏÑú drop\n",
        "    df_merged = df_merged.drop_duplicates(subset=[\"appid\",\"timestamp_created\"], keep=\"first\")\n",
        "    print(f\"‚Üí Ï§ëÎ≥µ Ï†úÍ±∞ ÌõÑ Ìñâ Ïàò: {len(df_merged)}\")\n",
        "else:\n",
        "    print(\"Ï§ëÎ≥µ ÏóÜÏùå ‚úÖ\")\n",
        "\n",
        "# Í≤∞Í≥º ÌôïÏù∏\n",
        "print(\"ÏµúÏ¢Ö Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞:\", df_merged.shape)\n",
        "print(df_merged.head())\n",
        "\n",
        "# Ï†ÄÏû•\n",
        "df_merged.to_csv(OUT_CSV, index=False)\n",
        "print(f\"Ï†ÄÏû• ÏôÑÎ£å ‚Üí {OUT_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FsTxnwp4lwG",
        "outputId": "18ee4e17-5e7b-4e62-cc0a-c268ffccb711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Í≤ΩÍ≥†] Ï§ëÎ≥µÎêú Îß§Ïπ≠ 12Í±¥ Î∞úÍ≤¨ (appid+timestamp_created Í∏∞Ï§Ä).\n",
            "         appid         timestamp_created\n",
            "7230   1091500 2020-12-10 00:51:06+00:00\n",
            "7231   1091500 2020-12-10 00:51:06+00:00\n",
            "7232   1091500 2020-12-10 00:51:06+00:00\n",
            "7233   1091500 2020-12-10 00:51:06+00:00\n",
            "24023  1277510 2021-01-28 02:48:07+00:00\n",
            "24024  1277510 2021-01-28 02:48:07+00:00\n",
            "24025  1277510 2021-01-28 02:48:07+00:00\n",
            "24026  1277510 2021-01-28 02:48:07+00:00\n",
            "46664  2096610 2022-11-17 19:14:42+00:00\n",
            "46665  2096610 2022-11-17 19:14:42+00:00\n",
            "‚Üí Ï§ëÎ≥µ Ï†úÍ±∞ ÌõÑ Ìñâ Ïàò: 104264\n",
            "ÏµúÏ¢Ö Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: (104264, 38)\n",
            "   recommendationid  appid            game     author_steamid  \\\n",
            "0         147449116     10  Counter-Strike  76561199183984450   \n",
            "1         147374264     10  Counter-Strike  76561198099573060   \n",
            "2         147357703     10  Counter-Strike  76561199080026894   \n",
            "3         147284743     10  Counter-Strike  76561199137893460   \n",
            "4         147263134     10  Counter-Strike  76561199013220131   \n",
            "\n",
            "   author_num_games_owned  author_num_reviews  author_playtime_forever  \\\n",
            "0                      51                  12                     2548   \n",
            "1                     226                  13                     2369   \n",
            "2                     118                  23                    13501   \n",
            "3                      19                   5                      543   \n",
            "4                      41                  10                     2510   \n",
            "\n",
            "   author_playtime_last_two_weeks  author_playtime_at_review  \\\n",
            "0                               0                       2480   \n",
            "1                               0                       2361   \n",
            "2                             212                      12957   \n",
            "3                              10                        526   \n",
            "4                               0                        221   \n",
            "\n",
            "    author_last_played  ... on_game_sale discount_max  \\\n",
            "0  2023-10-03 03:57:37  ...        False         80.0   \n",
            "1  2023-09-30 17:55:55  ...        False         80.0   \n",
            "2  2023-10-18 12:05:34  ...        False         80.0   \n",
            "3  2023-10-20 14:09:51  ...        False         80.0   \n",
            "4  2023-10-08 12:36:54  ...        False         80.0   \n",
            "\n",
            "              sale_start_utc               sale_end_utc  on_valve_event  \\\n",
            "0  2020-12-22 19:01:33+00:00  2020-12-22 19:01:33+00:00            True   \n",
            "1  2020-12-22 19:01:33+00:00  2020-12-22 19:01:33+00:00            True   \n",
            "2  2020-12-22 19:01:33+00:00  2020-12-22 19:01:33+00:00            True   \n",
            "3  2020-12-22 19:01:33+00:00  2020-12-22 19:01:33+00:00            True   \n",
            "4  2020-12-22 19:01:33+00:00  2020-12-22 19:01:33+00:00            True   \n",
            "\n",
            "             event_start_utc              event_end_utc  sale_context  \\\n",
            "0  2023-09-25 00:00:00+00:00  2023-10-02 00:00:00+00:00    event_only   \n",
            "1  2023-09-25 00:00:00+00:00  2023-10-02 00:00:00+00:00    event_only   \n",
            "2  2023-09-25 00:00:00+00:00  2023-10-02 00:00:00+00:00    event_only   \n",
            "3  2023-09-25 00:00:00+00:00  2023-10-02 00:00:00+00:00    event_only   \n",
            "4  2023-09-25 00:00:00+00:00  2023-10-02 00:00:00+00:00    event_only   \n",
            "\n",
            "   event_name  event_type  \n",
            "0  SHMUP Fest        fest  \n",
            "1  SHMUP Fest        fest  \n",
            "2  SHMUP Fest        fest  \n",
            "3  SHMUP Fest        fest  \n",
            "4  SHMUP Fest        fest  \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "Ï†ÄÏû• ÏôÑÎ£å ‚Üí /content/reviews_with_sale_flags_full.csv\n"
          ]
        }
      ]
    }
  ]
}
